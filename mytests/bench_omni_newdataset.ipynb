{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e0920c7",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [6]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e250dd08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T12:51:44.787112Z",
     "iopub.status.busy": "2024-06-28T12:51:44.786888Z",
     "iopub.status.idle": "2024-06-28T12:51:56.349330Z",
     "shell.execute_reply": "2024-06-28T12:51:56.348728Z"
    },
    "papermill": {
     "duration": 11.56814,
     "end_time": "2024-06-28T12:51:56.351096",
     "exception": false,
     "start_time": "2024-06-28T12:51:44.782956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ connected lamindb: jkobject/scprint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/appa/homes/jkalfon/scGPT/mytests/../scgpt/model/model.py:21: UserWarning: flash_attn is not installed\n",
      "  warnings.warn(\"flash_attn is not installed\")\n",
      "/pasteur/appa/homes/jkalfon/scGPT/mytests/../scgpt/model/multiomic_model.py:19: UserWarning: flash_attn is not installed\n",
      "  warnings.warn(\"flash_attn is not installed\")\n",
      "2024-06-28 14:51:53,414:INFO - PyTorch version 2.0.0 available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 14:51:53,417:INFO - JAX version 0.4.28 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "from anndata import AnnData\n",
    "\n",
    "from grnndata import GRNAnnData, from_embeddings\n",
    "from grnndata import utils\n",
    "\n",
    "from scdataloader import Preprocessor as myPreprocessor\n",
    "from bengrn import BenGRN, get_sroy_gt, get_perturb_gt\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "from scgpt_helper import prepare_model, prepare_dataset, generate_embedding, generate_grn\n",
    "import scgpt as scg\n",
    "from scgpt.tasks import GeneEmbedding\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.utils import set_seed\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch\n",
    "import torch\n",
    "\n",
    "\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38434de0",
   "metadata": {
    "papermill": {
     "duration": 0.003305,
     "end_time": "2024-06-28T12:51:56.358142",
     "exception": false,
     "start_time": "2024-06-28T12:51:56.354837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1: Load fine-tuned model and dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508999a",
   "metadata": {
    "papermill": {
     "duration": 0.003014,
     "end_time": "2024-06-28T12:51:56.364302",
     "exception": false,
     "start_time": "2024-06-28T12:51:56.361288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.1 Load fine-tuned model\n",
    "\n",
    "We are going to load a fine-tuned model for the gene interaction analysis on\n",
    "Adamson dataset. The fine-tuned model can be downloaded via this\n",
    "[link](https://drive.google.com/drive/folders/1HsPrwYGPXm867_u_Ye0W4Ch8AFSneXAn).\n",
    "The dataset will be loaded in the next step 1.2.\n",
    "\n",
    "To reproduce the provided fine-tuned model. Please followw the integration\n",
    "fin-tuning pipeline to fine-tune the pre-trained blood model on the Adamson\n",
    "perturbation dataset. Note that in the fine-tuning stage, we did not perform\n",
    "highly vairable gene selection but trained on the 5000+ genes present in the\n",
    "Adamson dataset. This is to provide flexbility in the inference stage to\n",
    "investigate changes in attention maps across different perturbation conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2faa07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T12:51:56.371861Z",
     "iopub.status.busy": "2024-06-28T12:51:56.371607Z",
     "iopub.status.idle": "2024-06-28T12:52:03.111413Z",
     "shell.execute_reply": "2024-06-28T12:52:03.110584Z"
    },
    "papermill": {
     "duration": 6.745644,
     "end_time": "2024-06-28T12:52:03.113083",
     "exception": false,
     "start_time": "2024-06-28T12:51:56.367439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume model from ../save/scGPT_human/best_model.pt, the model args will override the config ../save/scGPT_human/args.json.\n"
     ]
    }
   ],
   "source": [
    "model, vocab = prepare_model(model_dir=\"../save/scGPT_human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02e7489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T12:52:03.121519Z",
     "iopub.status.busy": "2024-06-28T12:52:03.121237Z",
     "iopub.status.idle": "2024-06-28T12:52:06.206942Z",
     "shell.execute_reply": "2024-06-28T12:52:06.206315Z"
    },
    "papermill": {
     "duration": 3.091305,
     "end_time": "2024-06-28T12:52:06.208434",
     "exception": false,
     "start_time": "2024-06-28T12:52:03.117129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpreprocessor = myPreprocessor(is_symbol=True, force_preprocess=True, skip_validate=True,\n",
    "                            do_postp=False, min_valid_genes_id=5000, min_dataset_size=64)\n",
    "\n",
    "genes = torch.load(\n",
    "#    '../../scPRINT/data/temp/vbd8bavn/epoch=17-step=90000.ckpt'\n",
    "    '/pasteur/zeus/projets/p02/ml4ig_hot/Users/jkalfon/scprint_scale/o2uniqsx/checkpoints/epoch=18-step=133000.ckpt'\n",
    ")['hyper_parameters']['genes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49cc2ad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T12:52:06.216370Z",
     "iopub.status.busy": "2024-06-28T12:52:06.216125Z",
     "iopub.status.idle": "2024-06-28T12:52:08.120570Z",
     "shell.execute_reply": "2024-06-28T12:52:08.119982Z"
    },
    "papermill": {
     "duration": 1.909727,
     "end_time": "2024-06-28T12:52:08.122071",
     "exception": false,
     "start_time": "2024-06-28T12:52:06.212344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CELLTYPES = [\n",
    "\"retinal rod cell\",\n",
    "\"Mueller cell\",\n",
    "\"amacrine cell\",\n",
    "\"ON-bipolar cell\",\n",
    "\"rod bipolar cell\",\n",
    "\"retinal cone cell\",\n",
    "\"retina horizontal cell\",\n",
    "\"retinal ganglion cell\",\n",
    "\"astrocyte\",\n",
    "\"microglial cell\",\n",
    "]\n",
    "\n",
    "MAXCELLS = 1024\n",
    "NUM_GENES = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4960333e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T12:52:08.130176Z",
     "iopub.status.busy": "2024-06-28T12:52:08.129693Z",
     "iopub.status.idle": "2024-06-28T12:52:10.908700Z",
     "shell.execute_reply": "2024-06-28T12:52:10.908164Z"
    },
    "papermill": {
     "duration": 2.784424,
     "end_time": "2024-06-28T12:52:10.909959",
     "exception": false,
     "start_time": "2024-06-28T12:52:08.125535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 51370 Ã— 70116\n",
       "    obs: 'biosample_id', 'donor_id', 'cell_type_ontology_term_id', 'organism_ontology_term_id', 'disease_ontology_term_id', 'tissue_ontology_term_id', 'assay_ontology_term_id', 'cell_type__custom', 'development_stage_ontology_term_id', 'sex_ontology_term_id', 'suspension_type', 'is_primary_data', 'age', 'self_reported_ethnicity_ontology_term_id', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'cell_culture', 'nnz', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'log1p_total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'log1p_total_counts_hb', 'pct_counts_hb', 'outlier', 'mt_outlier'\n",
       "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'uid', 'symbol', 'ncbi_gene_ids', 'biotype', 'description', 'synonyms', 'organism_id', 'public_source_id', 'created_by_id', 'mt', 'ribo', 'hb', 'organism', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'isTF'\n",
       "    uns: 'unseen_genes'\n",
       "    obsm: 'X_UMAP'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adata = sc.read_h5ad('/home/ml4ig1/scprint/.lamindb/gNNpgpo6gATjuxTE7CCp.h5ad')\n",
    "adata = sc.read_h5ad('../../scPRINT/data/gNNpgpo6gATjuxTE7CCp.h5ad')\n",
    "adata.var[\"isTF\"] = False\n",
    "adata.var.loc[adata.var.symbol.isin(utils.TF), \"isTF\"] = True\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65514c20",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a974ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T12:52:10.920142Z",
     "iopub.status.busy": "2024-06-28T12:52:10.919782Z",
     "iopub.status.idle": "2024-06-28T12:52:24.695663Z",
     "shell.execute_reply": "2024-06-28T12:52:24.694960Z"
    },
    "papermill": {
     "duration": 13.780858,
     "end_time": "2024-06-28T12:52:24.696603",
     "exception": true,
     "start_time": "2024-06-28T12:52:10.915745",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__contains__(): incompatible function arguments. The following argument types are supported:\n    1. (self: torchtext._torchtext.Vocab, arg0: str) -> bool\n\nInvoked with: <torchtext._torchtext.Vocab object at 0x7fa6bef5ba70>, nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m subadata \u001b[38;5;241m=\u001b[39m subadata[subadata\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m][:MAXCELLS, adata\u001b[38;5;241m.\u001b[39mvar\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(\n\u001b[1;32m     12\u001b[0m     genes) \u001b[38;5;241m&\u001b[39m adata\u001b[38;5;241m.\u001b[39mvar\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(to_use)]\n\u001b[1;32m     13\u001b[0m subadata\u001b[38;5;241m.\u001b[39mvar \u001b[38;5;241m=\u001b[39m subadata\u001b[38;5;241m.\u001b[39mvar\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m grn \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_grn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_attn_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscGPT_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mcelltype] \u001b[38;5;241m=\u001b[39m BenGRN(grn)\u001b[38;5;241m.\u001b[39mscprint_benchmark()\n\u001b[1;32m     16\u001b[0m grn\u001b[38;5;241m.\u001b[39mvarp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGRN\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m~\u001b[39mgrn\u001b[38;5;241m.\u001b[39mvar\u001b[38;5;241m.\u001b[39misTF,:]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/scGPT/mytests/scgpt_helper.py:166\u001b[0m, in \u001b[0;36mgenerate_grn\u001b[0;34m(model, vocab, adata, batch_size, num_attn_layers)\u001b[0m\n\u001b[1;32m    164\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m    165\u001b[0m dict_sum_condition \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m all_gene_ids, all_values, src_key_padding_mask, subadata \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Use this argument to specify which layer to extract the attention weights from\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Default to 11, extraction from the last (12th) layer. Note that index starts from 0\u001b[39;00m\n\u001b[1;32m    169\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/scGPT/mytests/scgpt_helper.py:106\u001b[0m, in \u001b[0;36mprepare_dataset\u001b[0;34m(subadata, vocab, data_is_raw, pad_token, n_bins, pad_value)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_dataset\u001b[39m(subadata, vocab, data_is_raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pad_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m51\u001b[39m, pad_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m--> 106\u001b[0m     subadata\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_in_vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gene \u001b[38;5;129;01min\u001b[39;00m vocab \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gene \u001b[38;5;129;01min\u001b[39;00m subadata\u001b[38;5;241m.\u001b[39mvar\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m    108\u001b[0m     ]\n\u001b[1;32m    109\u001b[0m     subadata \u001b[38;5;241m=\u001b[39m subadata[:, subadata\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_in_vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    111\u001b[0m     preprocessor \u001b[38;5;241m=\u001b[39m Preprocessor(\n\u001b[1;32m    112\u001b[0m         use_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# the key in adata.layers to use as raw data\u001b[39;00m\n\u001b[1;32m    113\u001b[0m         filter_gene_by_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# step 1\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m         result_binned_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_binned\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# the key in adata.layers to store the binned data\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     )\n",
      "File \u001b[0;32m~/scGPT/mytests/scgpt_helper.py:107\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_dataset\u001b[39m(subadata, vocab, data_is_raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pad_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m51\u001b[39m, pad_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    106\u001b[0m     subadata\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_in_vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 107\u001b[0m         \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mgene\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gene \u001b[38;5;129;01min\u001b[39;00m subadata\u001b[38;5;241m.\u001b[39mvar\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m    108\u001b[0m     ]\n\u001b[1;32m    109\u001b[0m     subadata \u001b[38;5;241m=\u001b[39m subadata[:, subadata\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_in_vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    111\u001b[0m     preprocessor \u001b[38;5;241m=\u001b[39m Preprocessor(\n\u001b[1;32m    112\u001b[0m         use_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# the key in adata.layers to use as raw data\u001b[39;00m\n\u001b[1;32m    113\u001b[0m         filter_gene_by_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# step 1\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m         result_binned_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_binned\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# the key in adata.layers to store the binned data\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/scprint17/lib/python3.10/site-packages/torchtext/vocab/vocab.py:54\u001b[0m, in \u001b[0;36mVocab.__contains__\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mexport\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, token: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m        token: The token for which to check the membership.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m        Whether the token is member of vocab or not.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__contains__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __contains__(): incompatible function arguments. The following argument types are supported:\n    1. (self: torchtext._torchtext.Vocab, arg0: str) -> bool\n\nInvoked with: <torchtext._torchtext.Vocab object at 0x7fa6bef5ba70>, nan"
     ]
    }
   ],
   "source": [
    "sc.tl.rank_genes_groups(\n",
    "    adata, groupby=\"cell_type\"\n",
    ")\n",
    "adata.var['ensembl_id'] = adata.var.index\n",
    "metrics = {}\n",
    "for celltype in CELLTYPES:\n",
    "    to_use = adata.uns[\"rank_genes_groups\"][\"names\"][celltype][\n",
    "        : NUM_GENES\n",
    "    ].tolist()\n",
    "    subadata = adata[adata.obs.cell_type == celltype]\n",
    "    subadata = subadata[subadata.X.sum(1) > 500][:MAXCELLS, adata.var.index.isin(\n",
    "        genes) & adata.var.index.isin(to_use)]\n",
    "    subadata.var = subadata.var.set_index('feature_name')\n",
    "    grn = generate_grn(model, vocab, subadata, batch_size = 10, num_attn_layers = 11)\n",
    "    metrics[\"scGPT_\"+celltype] = BenGRN(grn).scprint_benchmark()\n",
    "    grn.varp['GRN'][~grn.var.isTF,:]=0\n",
    "    metrics['scGPT_tf_'+celltype] = BenGRN(grn).scprint_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ed8f3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b311ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b1e22",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for k, v in metrics.items():\n",
    "    res.append([k.split('_')[-1], v['epr'], v['auprc'], v['rand_precision'], v['significant_enriched_TFtargets'], v.get('TF_enr', False), 'tf_' in k])\n",
    "\n",
    "df = pd.DataFrame(res, columns=['name','EPR', 'AUPRC', 'RAND', 'TF_targ', 'TF_enr', 'TF_only'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 44.520868,
   "end_time": "2024-06-28T12:52:27.962869",
   "environment_variables": {},
   "exception": true,
   "input_path": "bench_omni_newdataset.ipynb",
   "output_path": "bench_omni_newdataset.ipynb",
   "parameters": {},
   "start_time": "2024-06-28T12:51:43.442001",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}