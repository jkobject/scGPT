{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n",
      "/home/ml4ig1/miniconda3/envs/training-gpt/lib/python3.10/site-packages/wandb/sdk/launch/builder/build.py:11: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "/home/ml4ig1/miniconda3/envs/training-gpt/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/home/ml4ig1/miniconda3/envs/training-gpt/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/home/ml4ig1/miniconda3/envs/training-gpt/lib/python3.10/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "/home/ml4ig1/miniconda3/envs/training-gpt/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.logging')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/home/ml4ig1/miniconda3/envs/training-gpt/lib/python3.10/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('zope')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n",
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° lamindb instance: jkobject/scprint\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "\n",
    "from scgpt.trainer import eval_testdata as scgpt_test\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt.model import TransformerModel\n",
    "from scgpt.utils import load_pretrained\n",
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "from scgpt_helper import *\n",
    "\n",
    "import lamindb as ln\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment = scGExperiment()\n",
    "batch_keys = [\n",
    "    \"self_reported_ethnicity_ontology_term_id\",\n",
    "    \"assay_ontology_term_id\",\n",
    "]\n",
    "special_tokens = [\"<pad>\", \"<unk>\", \"<mask>\"]\n",
    "filter_gene_by_counts = 3\n",
    "data_is_raw = True\n",
    "save_path = \"../save/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = \"../save/scGPT_human/vocab.json\"\n",
    "model_path = \"../save/scGPT_human/best_model.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs √ó n_vars = 19694 √ó 37127\n",
       "    obs: 'n_genes', 'n_counts', 'percent_mito', 'donor_id', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'author_cell_type', 'suspension_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
       "    var: 'chromosome', 'featureend', 'featurestart', 'n_cells', 'percent_cells', 'robust', 'highly_variable_features', 'mean', 'var', 'hvf_loess', 'hvf_rank', 'gene_symbols', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
       "    uns: 'cell_type_ontology_term_id_colors', 'default_embedding', 'schema_version', 'title'\n",
       "    obsm: 'X_diffmap', 'X_diffmap_pca', 'X_fitsne', 'X_fle', 'X_pca', 'X_phi', 'X_umap'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = ln.File.filter(uid=ln.File.search(\"retina\").index[0]).one().load()\n",
    "# adata = ln.File.filter().first().load()\n",
    "#ln.Dataset.using(\"laminlabs/cellxgene-census\").one()\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - save to ../save/_retina-Dec08-15-13\n",
      "scGPT - INFO - match 25037/37127 genes in vocabulary of size 60697.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/Documents code/scGPT/mytests/scgpt_helper.py:141: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n",
      "  dataset.var[\"gene_ids\"] = vocab(dataset.var[\"gene_symbols\"].tolist())\n"
     ]
    }
   ],
   "source": [
    "save_dir = setup(dataset_name, save_path, config)\n",
    "\n",
    "if type(vocab) is str:\n",
    "    vocab = GeneVocab.from_file(vocab)\n",
    "vocab.set_default_index(vocab[config['pad_token']])\n",
    "\n",
    "dataset = load_dataset(adata, vocab)\n",
    "dataset.obs[\"batch_id\"] = dataset.obs[batch_keys].apply(\"_\".join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment.init_datamodule(dataset=, vocab=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Filtering genes by counts ...\n",
      "scGPT - INFO - Normalizing total counts ...\n",
      "scGPT - INFO - Log1p transforming ...\n",
      "WARNING: adata.X seems to be already log-transformed.\n",
      "scGPT - INFO - Subsetting highly variable genes ...\n",
      "scGPT - WARNING - No batch_key is provided, will use all cells for HVG selection.\n",
      "scGPT - INFO - Binning data ...\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=filter_gene_by_counts,  # step 1\n",
    "    filter_cell_by_counts=False,  # step 2\n",
    "    normalize_total=1e4,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=data_is_raw,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=config['n_hvg'],  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    binning=config['n_bins'],  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "\n",
    "preprocessor(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/training-gpt/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): GeneEncoder(\n",
       "    (embedding): Embedding(60697, 512, padding_idx=60694)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (value_encoder): ContinuousValueEncoder(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (linear1): Linear(in_features=1, out_features=512, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (batch_encoder): BatchLabelEncoder(\n",
       "    (embedding): Embedding(1, 512)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ExprDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cls_decoder): ClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=9, bias=True)\n",
       "  )\n",
       "  (mvc_decoder): MVCDecoder(\n",
       "    (gene2query): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (query_activation): Sigmoid()\n",
       "    (W): Linear(in_features=512, out_features=1024, bias=False)\n",
       "  )\n",
       "  (grad_reverse_discriminator): AdversarialDiscriminator(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       "  (creterion_cce): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerModel(\n",
    "    len(vocab),  # n_tokens\n",
    "    # TODO:\n",
    "    config['embsize'],\n",
    "    config['nhead'],\n",
    "    config['d_hid'],\n",
    "    config['nlayers'],\n",
    "    vocab=vocab,\n",
    "    n_cls=len(dataset.obs.cell_type.value_counts()),\n",
    "    dropout=config['dropout'],\n",
    "    pad_token=config['pad_token'],\n",
    "    pad_value=config['pad_value'],\n",
    "    do_mvc=config['MVC'],\n",
    "    do_dab=True,\n",
    "    use_batch_labels=True,\n",
    "    num_batch_labels=len(set(dataset.obs[\"batch_id\"])),\n",
    "    #domain_spec_batchnorm=config['dsbn'],\n",
    "    n_input_bins=config['n_bins'],\n",
    "    #ecs_threshold=config['ecs_thres'],\n",
    "    #explicit_zero_prob=config['explicit_zero_prob'],\n",
    "    use_fast_transformer=config['fast_transformer'],\n",
    "    #pre_norm=config['pre_norm'],\n",
    ")\n",
    "if model_path is not None:\n",
    "    load_pretrained(model, torch.load(model_path), verbose=False)\n",
    "    # model_config['file'] = model_dir / \"args.json\"\n",
    "    # model_file = model_dir / \"best_model.pt\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tune and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f9b427717e0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f9b43649a20, raw_cell=\"fine_tune(\n",
      "    model, \n",
      "    config,\n",
      "    dataset,\n",
      "  ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2Bperso/home/ml4ig1/Documents%20code/scGPT/mytests/cleanup_run.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/training-gpt/lib/python3.10/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:tqh5l1xw) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:914: ImportWarning: _SixMetaPathImporter.find_spec() not found; falling back to find_module()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autumn-silence-6</strong> at: <a href='https://wandb.ai/ml4ig/scGPT/runs/tqh5l1xw' target=\"_blank\">https://wandb.ai/ml4ig/scGPT/runs/tqh5l1xw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231208_153709-tqh5l1xw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:tqh5l1xw). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/training-gpt/lib/python3.10/site-packages/wandb/sdk/lib/ipython.py:89: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831d10a6699e4084bd9bcaaf3dc92b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113608677745409, max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/training-gpt/lib/python3.10/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ml4ig1/Documents code/scGPT/mytests/wandb/run-20231208_154606-igns0cxr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ml4ig/scGPT/runs/igns0cxr' target=\"_blank\">upbeat-salad-7</a></strong> to <a href='https://wandb.ai/ml4ig/scGPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ml4ig/scGPT' target=\"_blank\">https://wandb.ai/ml4ig/scGPT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ml4ig/scGPT/runs/igns0cxr' target=\"_blank\">https://wandb.ai/ml4ig/scGPT/runs/igns0cxr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - train set number of samples: 15755, \n",
      "\t feature length: 2001\n",
      "scGPT - INFO - valid set number of samples: 3939, \n",
      "\t feature length: 2001\n",
      "hey\n",
      "hey\n",
      "random masking at epoch   1, ratio of masked values in train:  0.3998\n",
      "scGPT - INFO - valid/loss: 23.255262877499884epoch 1\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   1 | time: 354.72s | valid loss/mse 23.2553\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - Best model with score 23.2553\n",
      "scGPT - INFO - train set number of samples: 15755, \n",
      "\t feature length: 2001\n",
      "scGPT - INFO - valid set number of samples: 3939, \n",
      "\t feature length: 2001\n",
      "hey\n",
      "hey\n",
      "random masking at epoch   2, ratio of masked values in train:  0.3998\n",
      "scGPT - INFO - valid/loss: 23.05727909433869epoch 2\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   2 | time: 360.93s | valid loss/mse 23.0573\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - Best model with score 23.0573\n",
      "scGPT - INFO - train set number of samples: 15755, \n",
      "\t feature length: 2001\n",
      "scGPT - INFO - valid set number of samples: 3939, \n",
      "\t feature length: 2001\n",
      "hey\n",
      "hey\n",
      "random masking at epoch   3, ratio of masked values in train:  0.3998\n",
      "scGPT - INFO - valid/loss: 22.52936708954392epoch 3\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   3 | time: 351.62s | valid loss/mse 22.5294\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - Best model with score 22.5294\n",
      "scGPT - INFO - train set number of samples: 15755, \n",
      "\t feature length: 2001\n",
      "scGPT - INFO - valid set number of samples: 3939, \n",
      "\t feature length: 2001\n",
      "hey\n",
      "hey\n",
      "random masking at epoch   4, ratio of masked values in train:  0.3998\n",
      "scGPT - INFO - valid/loss: 22.733733805462503epoch 4\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   4 | time: 356.54s | valid loss/mse 22.7337\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - train set number of samples: 15755, \n",
      "\t feature length: 2001\n",
      "scGPT - INFO - valid set number of samples: 3939, \n",
      "\t feature length: 2001\n",
      "hey\n",
      "hey\n",
      "random masking at epoch   5, ratio of masked values in train:  0.3998\n",
      "scGPT - INFO - valid/loss: 22.648576059508486epoch 5\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   5 | time: 354.64s | valid loss/mse 22.6486\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - train set number of samples: 15755, \n",
      "\t feature length: 2001\n",
      "scGPT - INFO - valid set number of samples: 3939, \n",
      "\t feature length: 2001\n",
      "hey\n",
      "hey\n",
      "random masking at epoch   6, ratio of masked values in train:  0.3998\n",
      "scGPT - INFO - valid/loss: 22.400173835144276epoch 6\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   6 | time: 345.79s | valid loss/mse 22.4002\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - Best model with score 22.4002\n",
      "scGPT - INFO - Saving model to ../save/\n",
      "> /home/ml4ig1/Documents code/scGPT/mytests/scgpt_helper.py(232)fine_tune()\n",
      "    230 \n",
      "    231     pdb.set_trace()\n",
      "--> 232     torch.save(\n",
      "    233         best_model.state_dict(),\n",
      "    234         save_folder + f\"model_e{best_model_epoch}.pt\",\n",
      "\n",
      "> /home/ml4ig1/Documents code/scGPT/mytests/scgpt_helper.py(233)fine_tune()\n",
      "    231     pdb.set_trace()\n",
      "    232     torch.save(\n",
      "--> 233         best_model.state_dict(),\n",
      "    234         save_folder + f\"model_e{best_model_epoch}.pt\",\n",
      "    235     )\n",
      "\n",
      "*** wandb.errors.CommError: 'NoneType' object has no attribute 'get'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/training-gpt/lib/python3.10/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/cls</td><td>‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÅ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ</td></tr><tr><td>train/gep</td><td>‚ñÇ‚ñÖ‚ñà‚ñÇ‚ñÑ‚ñá‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÑ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/cls</td><td>0.33092</td></tr><tr><td>train/gep</td><td>28.76307</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-salad-7</strong> at: <a href='https://wandb.ai/ml4ig/scGPT/runs/igns0cxr' target=\"_blank\">https://wandb.ai/ml4ig/scGPT/runs/igns0cxr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231208_154606-igns0cxr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fine_tune(\n",
    "    model, \n",
    "    config,\n",
    "    dataset,\n",
    "    vocab,\n",
    "    config['epochs'],\n",
    "    config['batch_size'],\n",
    "    save_path,\n",
    "    device,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): GeneEncoder(\n",
       "    (embedding): Embedding(60697, 512, padding_idx=60694)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (value_encoder): ContinuousValueEncoder(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (linear1): Linear(in_features=1, out_features=512, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (batch_encoder): BatchLabelEncoder(\n",
       "    (embedding): Embedding(1, 512)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ExprDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cls_decoder): ClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=9, bias=True)\n",
       "  )\n",
       "  (mvc_decoder): MVCDecoder(\n",
       "    (gene2query): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (query_activation): Sigmoid()\n",
       "    (W): Linear(in_features=512, out_features=1024, bias=False)\n",
       "  )\n",
       "  (grad_reverse_discriminator): AdversarialDiscriminator(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       "  (creterion_cce): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_pretrained(model, torch.load(save_path+\"/model_e6.pt\"), verbose=False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at what we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scgpt_test(\n",
    "    best_model, adata_test, gene_ids, vocab, config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
